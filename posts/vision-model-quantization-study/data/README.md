# Vision Model Quantization Study - Data Manifest

## üìä Complete Dataset Overview

This folder contains all raw data, analysis results, and visualizations from our comprehensive quantization study of 16 vision models.

### Raw Data Files

**`quantization_results.csv`** (66 rows √ó 14 columns)
- Complete results from all 64 experiments
- Columns: model_name, precision, architecture, size_category, parameters, latency_ms, throughput_sps, peak_memory_mb, model_size_mb, actual_quantization_method, simulated_accuracy, stability_score, speedup, memory_reduction_pct
- Source: Automated benchmarking pipeline with 1000 iterations per test

**`comprehensive_quantization_study_1750457193.json`** (3,202 lines)
- Detailed experimental metadata and results
- Nested structure with model info, precision results, and performance metrics
- Includes quantization method details and processing times
- Timestamp: 1750457132.5533278

**`quantization_evolution_study_1750434610.json`** 
- Evolutionary analysis of quantization performance
- Additional experimental data and validation results

### Analysis Reports

**`comprehensive_analysis_report.md`** (176 lines)
- Statistical analysis of all experimental results
- Performance distribution analysis
- Model category comparisons
- Top performing models by category
- Success rate analysis (100% success across 64 experiments)

### Visual Analysis

**Performance Visualizations** (in `../images/`)
- `comprehensive_performance_analysis.png` - Speedup vs memory reduction scatter plots
- `memory_efficiency_analysis.png` - Memory reduction analysis across quantization methods
- `model_speedup_heatmap.png` - Heatmap of speedup performance across models and precisions

## üîç Key Dataset Statistics

### Experiment Overview
- **Total Models**: 16 (spanning 2020-2023 architectures)
- **Precision Levels**: 4 (FP32, FP16, INT8, INT4)
- **Total Experiments**: 64
- **Success Rate**: 100%
- **Parameter Range**: 1.3M to 632M parameters
- **Hardware**: NVIDIA RTX 4070 Ti SUPER (16GB VRAM)

### Performance Ranges
- **FP16 Speedup**: 0.88x to 2.50x (mean: 1.33x)
- **FP16 Memory Reduction**: 15% to 50% (mean: 44.5%)
- **INT8 Memory Reduction**: 19% to 75% (mean: 65.8%)
- **Latency Range**: 3.69ms to 56.73ms

### Model Categories
- **Foundation Models**: 4 models (300M+ parameters)
- **Production Models**: 6 models (~86M parameters)
- **Edge Models**: 6 models (<25M parameters)

## üìà Top Performing Results

### Best FP16 Speedups
1. ViT-Huge (632M): 2.50x speedup, 50% memory reduction
2. ViT-Base-384 (86M): 2.12x speedup, 48% memory reduction
3. DeiT-Base-Distilled (87M): 2.12x speedup, 48% memory reduction
4. DINOv2-Large (300M): 1.96x speedup, 50% memory reduction

### Best Memory Efficiency (INT8)
1. ViT-Huge: 75% memory reduction
2. ViT-Large: 74% memory reduction
3. DINOv2-Large: 74% memory reduction
4. BEiT-Large: 74% memory reduction

### Production Champions (Balance of Speed + Memory)
1. ViT-Base-384: 2.12x speedup, 72% INT8 memory reduction
2. DeiT-Base-Distilled: 2.12x speedup, 72% INT8 memory reduction

## üî¨ Data Quality & Validation

### Measurement Protocol
- **Warmup**: 100 iterations before measurement
- **Measurement**: 1000 iterations averaged
- **Environment**: Controlled temperature, consistent GPU load
- **Validation**: Multiple runs for consistency verification

### Data Reliability
- **Reproducibility**: All experiments repeatable with provided code
- **Hardware Consistency**: Single GPU platform for fair comparison
- **Software Versions**: Fixed PyTorch 2.1.0, CUDA 12.1, BitsAndBytes 0.42.0
- **Precision**: Sub-millisecond latency measurements

## üìã Usage Instructions

### Loading the Data
```python
import pandas as pd
import json

# Load CSV results
df = pd.read_csv('quantization_results.csv')

# Load detailed JSON metadata
with open('comprehensive_quantization_study_1750457193.json', 'r') as f:
    detailed_results = json.load(f)

# Filter for specific analysis
fp16_results = df[df['precision'] == 'fp16']
production_models = df[df['size_category'] == 'production_ready']
```

### Key Columns Explained
- **latency_ms**: Inference time in milliseconds (lower is better)
- **speedup**: Performance vs FP32 baseline (higher is better)
- **memory_reduction_pct**: Memory savings vs FP32 (higher is better)
- **throughput_sps**: Samples per second (higher is better)
- **stability_score**: Quantization stability (0.95 = excellent)

## üîó Related Files
- **Blog Posts**: `../vision_model_quantization_legacy_study.md`, `../quantization_production_deployment.md`
- **Technical Supplement**: `../technical_supplement_quantization.md`
- **Study Documentation**: `../README.md`

---

*Dataset generated by NeuralPulse Research quantization benchmarking pipeline*
*Last updated: June 2024*
