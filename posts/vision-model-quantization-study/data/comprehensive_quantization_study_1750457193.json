{
  "study_metadata": {
    "timestamp": 1750457132.5533278,
    "study_name": "Comprehensive Vision Model Quantization Study: Production-Ready Models (2020-2023)",
    "models_tested": [
      "vit-huge-patch14-2020",
      "vit-large-patch16-2020",
      "dinov2-large-2023",
      "dinov2-base-2023",
      "beit-large-2021",
      "beit-base-pt22k-2021",
      "vit-base-384-production",
      "vit-base-224-production",
      "dino-vitb16-production",
      "dino-vits16-production",
      "deit-base-distilled-384-edge",
      "deit-small-distilled-224-edge",
      "mobilevit-small-edge",
      "mobilevit-xxs-edge",
      "deit-tiny-ultra-efficient",
      "vit-base-patch32-specialized"
    ],
    "precisions_tested": [
      "fp32",
      "fp16",
      "int8_bitsandbytes",
      "int4_nf4"
    ],
    "total_experiments": 64,
    "focus": "Established, production-ready vision models with proven quantization compatibility",
    "model_years": "2020-2023 (ViT 2020, DINO/BEiT/MobileViT 2021, DINOv2 2023)",
    "study_type": "Production quantization benchmarking of mature architectures",
    "success_rate": 100.0,
    "attempted_experiments": 64
  },
  "foundation_results": {
    "vit-huge-patch14-2020": {
      "model_info": {
        "model_id": "google/vit-huge-patch14-224-in21k",
        "name": "vit-huge-patch14-2020",
        "architecture": "ViT-Huge-2020",
        "category": "foundation_transformer",
        "year": "2020",
        "input_size": 224,
        "model_type": "vision_transformer",
        "parameters": "632M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "google/vit-huge-patch14-224-in21k",
          "model_name": "vit-huge-patch14-2020",
          "architecture": "ViT-Huge-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 2412.43,
          "inference_time_ms": 25.59,
          "throughput_imgs_per_sec": 39.08,
          "memory_usage_mb": 2420.56,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 555,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.74
        },
        "fp16": {
          "model_id": "google/vit-huge-patch14-224-in21k",
          "model_name": "vit-huge-patch14-2020",
          "architecture": "ViT-Huge-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 1206.22,
          "inference_time_ms": 10.24,
          "throughput_imgs_per_sec": 97.64,
          "memory_usage_mb": 1214.34,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 259,
            "total_layers": 555,
            "quantization_ratio": 0.467
          },
          "processing_time_sec": 0.39
        },
        "int8_bitsandbytes": {
          "model_id": "google/vit-huge-patch14-224-in21k",
          "model_name": "vit-huge-patch14-2020",
          "architecture": "ViT-Huge-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 606.22,
          "inference_time_ms": 56.14,
          "throughput_imgs_per_sec": 17.81,
          "memory_usage_mb": 615.82,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 555,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.44
        },
        "int4_nf4": {
          "model_id": "google/vit-huge-patch14-224-in21k",
          "model_name": "vit-huge-patch14-2020",
          "architecture": "ViT-Huge-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 606.22,
          "inference_time_ms": 56.54,
          "throughput_imgs_per_sec": 17.69,
          "memory_usage_mb": 615.82,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 555,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.43
        }
      }
    },
    "vit-large-patch16-2020": {
      "model_info": {
        "model_id": "google/vit-large-patch16-224-in21k",
        "name": "vit-large-patch16-2020",
        "architecture": "ViT-Large-2020",
        "category": "foundation_transformer",
        "year": "2020",
        "input_size": 224,
        "model_type": "vision_transformer",
        "parameters": "307M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "google/vit-large-patch16-224-in21k",
          "model_name": "vit-large-patch16-2020",
          "architecture": "ViT-Large-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 1161.01,
          "inference_time_ms": 9.84,
          "throughput_imgs_per_sec": 101.64,
          "memory_usage_mb": 1169.13,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 419,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.25
        },
        "fp16": {
          "model_id": "google/vit-large-patch16-224-in21k",
          "model_name": "vit-large-patch16-2020",
          "architecture": "ViT-Large-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 580.5,
          "inference_time_ms": 7.31,
          "throughput_imgs_per_sec": 136.82,
          "memory_usage_mb": 588.63,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 195,
            "total_layers": 419,
            "quantization_ratio": 0.465
          },
          "processing_time_sec": 0.19
        },
        "int8_bitsandbytes": {
          "model_id": "google/vit-large-patch16-224-in21k",
          "model_name": "vit-large-patch16-2020",
          "architecture": "ViT-Large-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 292.5,
          "inference_time_ms": 43.56,
          "throughput_imgs_per_sec": 22.95,
          "memory_usage_mb": 301.61,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 419,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.1
        },
        "int4_nf4": {
          "model_id": "google/vit-large-patch16-224-in21k",
          "model_name": "vit-large-patch16-2020",
          "architecture": "ViT-Large-2020",
          "category": "foundation_transformer",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 292.5,
          "inference_time_ms": 43.26,
          "throughput_imgs_per_sec": 23.12,
          "memory_usage_mb": 301.61,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 419,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.1
        }
      }
    },
    "dinov2-large-2023": {
      "model_info": {
        "model_id": "facebook/dinov2-large",
        "name": "dinov2-large-2023",
        "architecture": "DINOv2-Large-2023",
        "category": "self_supervised_2023",
        "year": "2023",
        "input_size": 224,
        "model_type": "self_supervised",
        "parameters": "300M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/dinov2-large",
          "model_name": "dinov2-large-2023",
          "architecture": "DINOv2-Large-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 1161.07,
          "inference_time_ms": 15.27,
          "throughput_imgs_per_sec": 65.5,
          "memory_usage_mb": 1169.2,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 440,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.36
        },
        "fp16": {
          "model_id": "facebook/dinov2-large",
          "model_name": "dinov2-large-2023",
          "architecture": "DINOv2-Large-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 580.54,
          "inference_time_ms": 7.78,
          "throughput_imgs_per_sec": 128.51,
          "memory_usage_mb": 588.77,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 194,
            "total_layers": 440,
            "quantization_ratio": 0.441
          },
          "processing_time_sec": 0.21
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/dinov2-large",
          "model_name": "dinov2-large-2023",
          "architecture": "DINOv2-Large-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 292.54,
          "inference_time_ms": 56.68,
          "throughput_imgs_per_sec": 17.64,
          "memory_usage_mb": 301.67,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 440,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.43
        },
        "int4_nf4": {
          "model_id": "facebook/dinov2-large",
          "model_name": "dinov2-large-2023",
          "architecture": "DINOv2-Large-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 292.54,
          "inference_time_ms": 56.73,
          "throughput_imgs_per_sec": 17.63,
          "memory_usage_mb": 301.67,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 440,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.43
        }
      }
    },
    "dinov2-base-2023": {
      "model_info": {
        "model_id": "facebook/dinov2-base",
        "name": "dinov2-base-2023",
        "architecture": "DINOv2-Base-2023",
        "category": "self_supervised_2023",
        "year": "2023",
        "input_size": 224,
        "model_type": "self_supervised",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/dinov2-base",
          "model_name": "dinov2-base-2023",
          "architecture": "DINOv2-Base-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 330.28,
          "inference_time_ms": 5.69,
          "throughput_imgs_per_sec": 175.87,
          "memory_usage_mb": 339.29,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 224,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.14
        },
        "fp16": {
          "model_id": "facebook/dinov2-base",
          "model_name": "dinov2-base-2023",
          "architecture": "DINOv2-Base-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 165.14,
          "inference_time_ms": 4.03,
          "throughput_imgs_per_sec": 248.08,
          "memory_usage_mb": 175.13,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 98,
            "total_layers": 224,
            "quantization_ratio": 0.438
          },
          "processing_time_sec": 0.11
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/dinov2-base",
          "model_name": "dinov2-base-2023",
          "architecture": "DINOv2-Base-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.14,
          "inference_time_ms": 29.01,
          "throughput_imgs_per_sec": 34.48,
          "memory_usage_mb": 92.61,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 224,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.73
        },
        "int4_nf4": {
          "model_id": "facebook/dinov2-base",
          "model_name": "dinov2-base-2023",
          "architecture": "DINOv2-Base-2023",
          "category": "self_supervised_2023",
          "year": "2023",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.14,
          "inference_time_ms": 29.35,
          "throughput_imgs_per_sec": 34.07,
          "memory_usage_mb": 92.61,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 224,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.74
        }
      }
    },
    "beit-large-2021": {
      "model_info": {
        "model_id": "microsoft/beit-large-patch16-224",
        "name": "beit-large-2021",
        "architecture": "BEiT-Large-2021",
        "category": "masked_autoencoder_2021",
        "year": "2021",
        "input_size": 224,
        "model_type": "vision_transformer",
        "parameters": "307M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "microsoft/beit-large-patch16-224",
          "model_name": "beit-large-2021",
          "architecture": "BEiT-Large-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 1157.4,
          "inference_time_ms": 12.31,
          "throughput_imgs_per_sec": 81.23,
          "memory_usage_mb": 1165.53,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 490,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.33
        },
        "fp16": {
          "model_id": "microsoft/beit-large-patch16-224",
          "model_name": "beit-large-2021",
          "architecture": "BEiT-Large-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 578.7,
          "inference_time_ms": 10.71,
          "throughput_imgs_per_sec": 93.35,
          "memory_usage_mb": 587.91,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 194,
            "total_layers": 490,
            "quantization_ratio": 0.396
          },
          "processing_time_sec": 0.28
        },
        "int8_bitsandbytes": {
          "model_id": "microsoft/beit-large-patch16-224",
          "model_name": "beit-large-2021",
          "architecture": "BEiT-Large-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 290.7,
          "inference_time_ms": 59.32,
          "throughput_imgs_per_sec": 16.86,
          "memory_usage_mb": 299.74,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 490,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.51
        },
        "int4_nf4": {
          "model_id": "microsoft/beit-large-patch16-224",
          "model_name": "beit-large-2021",
          "architecture": "BEiT-Large-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 290.7,
          "inference_time_ms": 59.48,
          "throughput_imgs_per_sec": 16.81,
          "memory_usage_mb": 300.28,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 490,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 1.51
        }
      }
    },
    "beit-base-pt22k-2021": {
      "model_info": {
        "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
        "name": "beit-base-pt22k-2021",
        "architecture": "BEiT-Base-PT22K-2021",
        "category": "masked_autoencoder_2021",
        "year": "2021",
        "input_size": 224,
        "model_type": "masked_transformer",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
          "model_name": "beit-base-pt22k-2021",
          "architecture": "BEiT-Base-PT22K-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 327.16,
          "inference_time_ms": 5.7,
          "throughput_imgs_per_sec": 175.38,
          "memory_usage_mb": 336.36,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 250,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.15
        },
        "fp16": {
          "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
          "model_name": "beit-base-pt22k-2021",
          "architecture": "BEiT-Base-PT22K-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 163.58,
          "inference_time_ms": 5.67,
          "throughput_imgs_per_sec": 176.4,
          "memory_usage_mb": 174.44,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 98,
            "total_layers": 250,
            "quantization_ratio": 0.392
          },
          "processing_time_sec": 0.15
        },
        "int8_bitsandbytes": {
          "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
          "model_name": "beit-base-pt22k-2021",
          "architecture": "BEiT-Base-PT22K-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 82.58,
          "inference_time_ms": 30.2,
          "throughput_imgs_per_sec": 33.11,
          "memory_usage_mb": 92.88,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 250,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.77
        },
        "int4_nf4": {
          "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
          "model_name": "beit-base-pt22k-2021",
          "architecture": "BEiT-Base-PT22K-2021",
          "category": "masked_autoencoder_2021",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 82.58,
          "inference_time_ms": 30.83,
          "throughput_imgs_per_sec": 32.44,
          "memory_usage_mb": 93.08,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 250,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.79
        }
      }
    }
  },
  "production_results": {
    "vit-base-384-production": {
      "model_info": {
        "model_id": "google/vit-base-patch16-384",
        "name": "vit-base-384-production",
        "architecture": "ViT-Base-384-Production",
        "category": "production_ready",
        "year": "2020",
        "input_size": 384,
        "model_type": "vision_transformer",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "google/vit-base-patch16-384",
          "model_name": "vit-base-384-production",
          "architecture": "ViT-Base-384-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 330.66,
          "inference_time_ms": 8.07,
          "throughput_imgs_per_sec": 123.89,
          "memory_usage_mb": 340.88,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.18
        },
        "fp16": {
          "model_id": "google/vit-base-patch16-384",
          "model_name": "vit-base-384-production",
          "architecture": "ViT-Base-384-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 165.33,
          "inference_time_ms": 3.8,
          "throughput_imgs_per_sec": 262.86,
          "memory_usage_mb": 176.8,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "google/vit-base-patch16-384",
          "model_name": "vit-base-384-production",
          "architecture": "ViT-Base-384-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.33,
          "inference_time_ms": 21.86,
          "throughput_imgs_per_sec": 45.74,
          "memory_usage_mb": 95.5,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.55
        },
        "int4_nf4": {
          "model_id": "google/vit-base-patch16-384",
          "model_name": "vit-base-384-production",
          "architecture": "ViT-Base-384-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.33,
          "inference_time_ms": 22.26,
          "throughput_imgs_per_sec": 44.93,
          "memory_usage_mb": 95.5,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.56
        }
      }
    },
    "vit-base-224-production": {
      "model_info": {
        "model_id": "google/vit-base-patch16-224-in21k",
        "name": "vit-base-224-production",
        "architecture": "ViT-Base-224-Production",
        "category": "production_ready",
        "year": "2020",
        "input_size": 224,
        "model_type": "vision_transformer",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "google/vit-base-patch16-224-in21k",
          "model_name": "vit-base-224-production",
          "architecture": "ViT-Base-224-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 329.55,
          "inference_time_ms": 3.83,
          "throughput_imgs_per_sec": 260.76,
          "memory_usage_mb": 339.77,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "google/vit-base-patch16-224-in21k",
          "model_name": "vit-base-224-production",
          "architecture": "ViT-Base-224-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 164.77,
          "inference_time_ms": 3.81,
          "throughput_imgs_per_sec": 262.44,
          "memory_usage_mb": 176.25,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "google/vit-base-patch16-224-in21k",
          "model_name": "vit-base-224-production",
          "architecture": "ViT-Base-224-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 83.77,
          "inference_time_ms": 21.89,
          "throughput_imgs_per_sec": 45.68,
          "memory_usage_mb": 94.95,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.55
        },
        "int4_nf4": {
          "model_id": "google/vit-base-patch16-224-in21k",
          "model_name": "vit-base-224-production",
          "architecture": "ViT-Base-224-Production",
          "category": "production_ready",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 83.77,
          "inference_time_ms": 22.04,
          "throughput_imgs_per_sec": 45.38,
          "memory_usage_mb": 94.95,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.56
        }
      }
    },
    "dino-vitb16-production": {
      "model_info": {
        "model_id": "facebook/dino-vitb16",
        "name": "dino-vitb16-production",
        "architecture": "DINO-ViT-Base-Production",
        "category": "production_ready",
        "year": "2021",
        "input_size": 224,
        "model_type": "self_supervised",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/dino-vitb16",
          "model_name": "dino-vitb16-production",
          "architecture": "DINO-ViT-Base-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 329.55,
          "inference_time_ms": 3.82,
          "throughput_imgs_per_sec": 261.64,
          "memory_usage_mb": 339.77,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "facebook/dino-vitb16",
          "model_name": "dino-vitb16-production",
          "architecture": "DINO-ViT-Base-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 164.77,
          "inference_time_ms": 3.88,
          "throughput_imgs_per_sec": 257.52,
          "memory_usage_mb": 176.25,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/dino-vitb16",
          "model_name": "dino-vitb16-production",
          "architecture": "DINO-ViT-Base-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 83.77,
          "inference_time_ms": 27.53,
          "throughput_imgs_per_sec": 36.32,
          "memory_usage_mb": 95.0,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.7
        },
        "int4_nf4": {
          "model_id": "facebook/dino-vitb16",
          "model_name": "dino-vitb16-production",
          "architecture": "DINO-ViT-Base-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 83.77,
          "inference_time_ms": 27.34,
          "throughput_imgs_per_sec": 36.57,
          "memory_usage_mb": 95.0,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.69
        }
      }
    },
    "dino-vits16-production": {
      "model_info": {
        "model_id": "facebook/dino-vits16",
        "name": "dino-vits16-production",
        "architecture": "DINO-ViT-Small-Production",
        "category": "production_ready",
        "year": "2021",
        "input_size": 224,
        "model_type": "self_supervised",
        "parameters": "22M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/dino-vits16",
          "model_name": "dino-vits16-production",
          "architecture": "DINO-ViT-Small-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 83.21,
          "inference_time_ms": 3.74,
          "throughput_imgs_per_sec": 267.69,
          "memory_usage_mb": 93.56,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "facebook/dino-vits16",
          "model_name": "dino-vits16-production",
          "architecture": "DINO-ViT-Small-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 41.61,
          "inference_time_ms": 3.89,
          "throughput_imgs_per_sec": 257.34,
          "memory_usage_mb": 52.48,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/dino-vits16",
          "model_name": "dino-vits16-production",
          "architecture": "DINO-ViT-Small-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 21.36,
          "inference_time_ms": 28.45,
          "throughput_imgs_per_sec": 35.15,
          "memory_usage_mb": 31.82,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.71
        },
        "int4_nf4": {
          "model_id": "facebook/dino-vits16",
          "model_name": "dino-vits16-production",
          "architecture": "DINO-ViT-Small-Production",
          "category": "production_ready",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 21.36,
          "inference_time_ms": 26.81,
          "throughput_imgs_per_sec": 37.3,
          "memory_usage_mb": 31.82,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.67
        }
      }
    }
  },
  "efficiency_results": {
    "deit-base-distilled-384-edge": {
      "model_info": {
        "model_id": "facebook/deit-base-distilled-patch16-384",
        "name": "deit-base-distilled-384-edge",
        "architecture": "DeiT-Base-Distilled-Edge",
        "category": "edge_optimized",
        "year": "2020",
        "input_size": 384,
        "model_type": "distilled_transformer",
        "parameters": "87M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/deit-base-distilled-patch16-384",
          "model_name": "deit-base-distilled-384-edge",
          "architecture": "DeiT-Base-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 330.67,
          "inference_time_ms": 8.07,
          "throughput_imgs_per_sec": 123.99,
          "memory_usage_mb": 340.89,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.18
        },
        "fp16": {
          "model_id": "facebook/deit-base-distilled-patch16-384",
          "model_name": "deit-base-distilled-384-edge",
          "architecture": "DeiT-Base-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 165.33,
          "inference_time_ms": 3.81,
          "throughput_imgs_per_sec": 262.71,
          "memory_usage_mb": 176.81,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/deit-base-distilled-patch16-384",
          "model_name": "deit-base-distilled-384-edge",
          "architecture": "DeiT-Base-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.33,
          "inference_time_ms": 28.51,
          "throughput_imgs_per_sec": 35.08,
          "memory_usage_mb": 95.54,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.72
        },
        "int4_nf4": {
          "model_id": "facebook/deit-base-distilled-patch16-384",
          "model_name": "deit-base-distilled-384-edge",
          "architecture": "DeiT-Base-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 84.33,
          "inference_time_ms": 28.09,
          "throughput_imgs_per_sec": 35.6,
          "memory_usage_mb": 95.54,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.71
        }
      }
    },
    "deit-small-distilled-224-edge": {
      "model_info": {
        "model_id": "facebook/deit-small-distilled-patch16-224",
        "name": "deit-small-distilled-224-edge",
        "architecture": "DeiT-Small-Distilled-Edge",
        "category": "edge_optimized",
        "year": "2020",
        "input_size": 224,
        "model_type": "distilled_transformer",
        "parameters": "22M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/deit-small-distilled-patch16-224",
          "model_name": "deit-small-distilled-224-edge",
          "architecture": "DeiT-Small-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 83.21,
          "inference_time_ms": 3.77,
          "throughput_imgs_per_sec": 265.0,
          "memory_usage_mb": 91.47,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "facebook/deit-small-distilled-patch16-224",
          "model_name": "deit-small-distilled-224-edge",
          "architecture": "DeiT-Small-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 41.61,
          "inference_time_ms": 3.94,
          "throughput_imgs_per_sec": 253.56,
          "memory_usage_mb": 50.39,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/deit-small-distilled-patch16-224",
          "model_name": "deit-small-distilled-224-edge",
          "architecture": "DeiT-Small-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 21.36,
          "inference_time_ms": 26.91,
          "throughput_imgs_per_sec": 37.16,
          "memory_usage_mb": 29.69,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.68
        },
        "int4_nf4": {
          "model_id": "facebook/deit-small-distilled-patch16-224",
          "model_name": "deit-small-distilled-224-edge",
          "architecture": "DeiT-Small-Distilled-Edge",
          "category": "edge_optimized",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 21.36,
          "inference_time_ms": 27.11,
          "throughput_imgs_per_sec": 36.88,
          "memory_usage_mb": 29.69,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.68
        }
      }
    },
    "mobilevit-small-edge": {
      "model_info": {
        "model_id": "timm/mobilevit_s.cvnets_in1k",
        "name": "mobilevit-small-edge",
        "architecture": "MobileViT-Small-Edge",
        "category": "edge_optimized",
        "year": "2021",
        "input_size": 256,
        "model_type": "mobile_transformer",
        "parameters": "5.6M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "timm/mobilevit_s.cvnets_in1k",
          "model_name": "mobilevit-small-edge",
          "architecture": "MobileViT-Small-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 18.88,
          "inference_time_ms": 4.32,
          "throughput_imgs_per_sec": 231.33,
          "memory_usage_mb": 27.19,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 420,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.14
        },
        "fp16": {
          "model_id": "timm/mobilevit_s.cvnets_in1k",
          "model_name": "mobilevit-small-edge",
          "architecture": "MobileViT-Small-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 9.44,
          "inference_time_ms": 4.91,
          "throughput_imgs_per_sec": 203.67,
          "memory_usage_mb": 17.62,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 124,
            "total_layers": 420,
            "quantization_ratio": 0.295
          },
          "processing_time_sec": 0.16
        },
        "int8_bitsandbytes": {
          "model_id": "timm/mobilevit_s.cvnets_in1k",
          "model_name": "mobilevit-small-edge",
          "architecture": "MobileViT-Small-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 6.68,
          "inference_time_ms": 12.76,
          "throughput_imgs_per_sec": 78.35,
          "memory_usage_mb": 14.92,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 420,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.32
        },
        "int4_nf4": {
          "model_id": "timm/mobilevit_s.cvnets_in1k",
          "model_name": "mobilevit-small-edge",
          "architecture": "MobileViT-Small-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 6.68,
          "inference_time_ms": 12.9,
          "throughput_imgs_per_sec": 77.54,
          "memory_usage_mb": 14.92,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 420,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.33
        }
      }
    },
    "mobilevit-xxs-edge": {
      "model_info": {
        "model_id": "apple/mobilevit-xx-small",
        "name": "mobilevit-xxs-edge",
        "architecture": "MobileViT-XXS-Edge",
        "category": "edge_optimized",
        "year": "2021",
        "input_size": 256,
        "model_type": "mobile_transformer",
        "parameters": "1.3M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "apple/mobilevit-xx-small",
          "model_name": "mobilevit-xxs-edge",
          "architecture": "MobileViT-XXS-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 3.64,
          "inference_time_ms": 5.15,
          "throughput_imgs_per_sec": 194.24,
          "memory_usage_mb": 11.84,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 315,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.15
        },
        "fp16": {
          "model_id": "apple/mobilevit-xx-small",
          "model_name": "mobilevit-xxs-edge",
          "architecture": "MobileViT-XXS-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 1.82,
          "inference_time_ms": 5.59,
          "throughput_imgs_per_sec": 178.78,
          "memory_usage_mb": 10.04,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 142,
            "total_layers": 315,
            "quantization_ratio": 0.451
          },
          "processing_time_sec": 0.17
        },
        "int8_bitsandbytes": {
          "model_id": "apple/mobilevit-xx-small",
          "model_name": "mobilevit-xxs-edge",
          "architecture": "MobileViT-XXS-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 1.35,
          "inference_time_ms": 16.91,
          "throughput_imgs_per_sec": 59.13,
          "memory_usage_mb": 9.61,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 315,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.43
        },
        "int4_nf4": {
          "model_id": "apple/mobilevit-xx-small",
          "model_name": "mobilevit-xxs-edge",
          "architecture": "MobileViT-XXS-Edge",
          "category": "edge_optimized",
          "year": "2021",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 1.35,
          "inference_time_ms": 17.16,
          "throughput_imgs_per_sec": 58.28,
          "memory_usage_mb": 9.61,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 315,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.43
        }
      }
    },
    "deit-tiny-ultra-efficient": {
      "model_info": {
        "model_id": "facebook/deit-tiny-patch16-224",
        "name": "deit-tiny-ultra-efficient",
        "architecture": "DeiT-Tiny-Ultra-Efficient",
        "category": "specialized_efficient",
        "year": "2020",
        "input_size": 224,
        "model_type": "efficient_transformer",
        "parameters": "5.7M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "facebook/deit-tiny-patch16-224",
          "model_name": "deit-tiny-ultra-efficient",
          "architecture": "DeiT-Tiny-Ultra-Efficient",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 21.22,
          "inference_time_ms": 3.69,
          "throughput_imgs_per_sec": 271.21,
          "memory_usage_mb": 29.37,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "facebook/deit-tiny-patch16-224",
          "model_name": "deit-tiny-ultra-efficient",
          "architecture": "DeiT-Tiny-Ultra-Efficient",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 10.61,
          "inference_time_ms": 3.87,
          "throughput_imgs_per_sec": 258.48,
          "memory_usage_mb": 18.75,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "facebook/deit-tiny-patch16-224",
          "model_name": "deit-tiny-ultra-efficient",
          "architecture": "DeiT-Tiny-Ultra-Efficient",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 5.55,
          "inference_time_ms": 25.73,
          "throughput_imgs_per_sec": 38.86,
          "memory_usage_mb": 13.8,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.65
        },
        "int4_nf4": {
          "model_id": "facebook/deit-tiny-patch16-224",
          "model_name": "deit-tiny-ultra-efficient",
          "architecture": "DeiT-Tiny-Ultra-Efficient",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 5.55,
          "inference_time_ms": 25.55,
          "throughput_imgs_per_sec": 39.14,
          "memory_usage_mb": 13.8,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.65
        }
      }
    },
    "vit-base-patch32-specialized": {
      "model_info": {
        "model_id": "google/vit-base-patch32-224-in21k",
        "name": "vit-base-patch32-specialized",
        "architecture": "ViT-Base-Patch32-Specialized",
        "category": "specialized_efficient",
        "year": "2020",
        "input_size": 224,
        "model_type": "vision_transformer",
        "parameters": "86M"
      },
      "precision_results": {
        "fp32": {
          "model_id": "google/vit-base-patch32-224-in21k",
          "model_name": "vit-base-patch32-specialized",
          "architecture": "ViT-Base-Patch32-Specialized",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "fp32",
          "actual_quantization_method": "fp32_baseline",
          "model_size_mb": 335.87,
          "inference_time_ms": 3.69,
          "throughput_imgs_per_sec": 271.28,
          "memory_usage_mb": 343.99,
          "quantization_method": "baseline_fp32_full_precision",
          "quantization_info": {
            "precision": "fp32",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.1
        },
        "fp16": {
          "model_id": "google/vit-base-patch32-224-in21k",
          "model_name": "vit-base-patch32-specialized",
          "architecture": "ViT-Base-Patch32-Specialized",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "fp16",
          "actual_quantization_method": "fp16_half_precision",
          "model_size_mb": 167.93,
          "inference_time_ms": 3.78,
          "throughput_imgs_per_sec": 264.79,
          "memory_usage_mb": 176.68,
          "quantization_method": "half_precision_conversion",
          "quantization_info": {
            "precision": "fp16",
            "quantized_layers": 99,
            "total_layers": 215,
            "quantization_ratio": 0.46
          },
          "processing_time_sec": 0.1
        },
        "int8_bitsandbytes": {
          "model_id": "google/vit-base-patch32-224-in21k",
          "model_name": "vit-base-patch32-specialized",
          "architecture": "ViT-Base-Patch32-Specialized",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "int8_bitsandbytes",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 86.93,
          "inference_time_ms": 21.3,
          "throughput_imgs_per_sec": 46.95,
          "memory_usage_mb": 95.51,
          "quantization_method": "8bit_linear_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int8_bitsandbytes",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.54
        },
        "int4_nf4": {
          "model_id": "google/vit-base-patch32-224-in21k",
          "model_name": "vit-base-patch32-specialized",
          "architecture": "ViT-Base-Patch32-Specialized",
          "category": "specialized_efficient",
          "year": "2020",
          "precision": "int4_nf4",
          "actual_quantization_method": "bitsandbytes_int8_success",
          "model_size_mb": 86.93,
          "inference_time_ms": 21.42,
          "throughput_imgs_per_sec": 46.68,
          "memory_usage_mb": 95.51,
          "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
          "quantization_info": {
            "precision": "int4_nf4",
            "quantized_layers": 0,
            "total_layers": 215,
            "quantization_ratio": 0.0
          },
          "processing_time_sec": 0.54
        }
      }
    }
  },
  "comprehensive_analysis": {
    "executive_summary": {
      "total_models_tested": 16,
      "foundation_models_count": 6,
      "production_models_count": 4,
      "efficiency_models_count": 6,
      "success_rate": 100.0,
      "successful_experiments": 64,
      "failed_experiments": 0
    },
    "quantization_effectiveness": {
      "size_reduction_analysis": {
        "vit-huge-patch14-2020_fp16": {
          "original_size_mb": 2412.43,
          "quantized_size_mb": 1206.22,
          "reduction_percent": 50.0
        },
        "vit-large-patch16-2020_fp16": {
          "original_size_mb": 1161.01,
          "quantized_size_mb": 580.5,
          "reduction_percent": 50.0
        },
        "dinov2-large-2023_fp16": {
          "original_size_mb": 1161.07,
          "quantized_size_mb": 580.54,
          "reduction_percent": 50.0
        },
        "dinov2-base-2023_fp16": {
          "original_size_mb": 330.28,
          "quantized_size_mb": 165.14,
          "reduction_percent": 50.0
        },
        "beit-large-2021_fp16": {
          "original_size_mb": 1157.4,
          "quantized_size_mb": 578.7,
          "reduction_percent": 50.0
        },
        "beit-base-pt22k-2021_fp16": {
          "original_size_mb": 327.16,
          "quantized_size_mb": 163.58,
          "reduction_percent": 50.0
        },
        "vit-base-384-production_fp16": {
          "original_size_mb": 330.66,
          "quantized_size_mb": 165.33,
          "reduction_percent": 50.0
        },
        "vit-base-224-production_fp16": {
          "original_size_mb": 329.55,
          "quantized_size_mb": 164.77,
          "reduction_percent": 50.0
        },
        "dino-vitb16-production_fp16": {
          "original_size_mb": 329.55,
          "quantized_size_mb": 164.77,
          "reduction_percent": 50.0
        },
        "dino-vits16-production_fp16": {
          "original_size_mb": 83.21,
          "quantized_size_mb": 41.61,
          "reduction_percent": 50.0
        },
        "deit-base-distilled-384-edge_fp16": {
          "original_size_mb": 330.67,
          "quantized_size_mb": 165.33,
          "reduction_percent": 50.0
        },
        "deit-small-distilled-224-edge_fp16": {
          "original_size_mb": 83.21,
          "quantized_size_mb": 41.61,
          "reduction_percent": 50.0
        },
        "mobilevit-small-edge_fp16": {
          "original_size_mb": 18.88,
          "quantized_size_mb": 9.44,
          "reduction_percent": 50.0
        },
        "mobilevit-xxs-edge_fp16": {
          "original_size_mb": 3.64,
          "quantized_size_mb": 1.82,
          "reduction_percent": 50.0
        },
        "deit-tiny-ultra-efficient_fp16": {
          "original_size_mb": 21.22,
          "quantized_size_mb": 10.61,
          "reduction_percent": 50.0
        },
        "vit-base-patch32-specialized_fp16": {
          "original_size_mb": 335.87,
          "quantized_size_mb": 167.93,
          "reduction_percent": 50.0
        }
      },
      "performance_impact": {},
      "quantization_success_rates": {}
    },
    "architecture_comparison": {
      "foundation_models": [],
      "production_models": [
        {
          "name": "vit-base-384-production",
          "architecture": "ViT-Base-384-Production",
          "category": "production_ready",
          "results": {
            "fp32": {
              "model_id": "google/vit-base-patch16-384",
              "model_name": "vit-base-384-production",
              "architecture": "ViT-Base-384-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 330.66,
              "inference_time_ms": 8.07,
              "throughput_imgs_per_sec": 123.89,
              "memory_usage_mb": 340.88,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.18
            },
            "fp16": {
              "model_id": "google/vit-base-patch16-384",
              "model_name": "vit-base-384-production",
              "architecture": "ViT-Base-384-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 165.33,
              "inference_time_ms": 3.8,
              "throughput_imgs_per_sec": 262.86,
              "memory_usage_mb": 176.8,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "google/vit-base-patch16-384",
              "model_name": "vit-base-384-production",
              "architecture": "ViT-Base-384-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.33,
              "inference_time_ms": 21.86,
              "throughput_imgs_per_sec": 45.74,
              "memory_usage_mb": 95.5,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.55
            },
            "int4_nf4": {
              "model_id": "google/vit-base-patch16-384",
              "model_name": "vit-base-384-production",
              "architecture": "ViT-Base-384-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.33,
              "inference_time_ms": 22.26,
              "throughput_imgs_per_sec": 44.93,
              "memory_usage_mb": 95.5,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.56
            }
          }
        },
        {
          "name": "vit-base-224-production",
          "architecture": "ViT-Base-224-Production",
          "category": "production_ready",
          "results": {
            "fp32": {
              "model_id": "google/vit-base-patch16-224-in21k",
              "model_name": "vit-base-224-production",
              "architecture": "ViT-Base-224-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 329.55,
              "inference_time_ms": 3.83,
              "throughput_imgs_per_sec": 260.76,
              "memory_usage_mb": 339.77,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "google/vit-base-patch16-224-in21k",
              "model_name": "vit-base-224-production",
              "architecture": "ViT-Base-224-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 164.77,
              "inference_time_ms": 3.81,
              "throughput_imgs_per_sec": 262.44,
              "memory_usage_mb": 176.25,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "google/vit-base-patch16-224-in21k",
              "model_name": "vit-base-224-production",
              "architecture": "ViT-Base-224-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 83.77,
              "inference_time_ms": 21.89,
              "throughput_imgs_per_sec": 45.68,
              "memory_usage_mb": 94.95,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.55
            },
            "int4_nf4": {
              "model_id": "google/vit-base-patch16-224-in21k",
              "model_name": "vit-base-224-production",
              "architecture": "ViT-Base-224-Production",
              "category": "production_ready",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 83.77,
              "inference_time_ms": 22.04,
              "throughput_imgs_per_sec": 45.38,
              "memory_usage_mb": 94.95,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.56
            }
          }
        },
        {
          "name": "dino-vitb16-production",
          "architecture": "DINO-ViT-Base-Production",
          "category": "production_ready",
          "results": {
            "fp32": {
              "model_id": "facebook/dino-vitb16",
              "model_name": "dino-vitb16-production",
              "architecture": "DINO-ViT-Base-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 329.55,
              "inference_time_ms": 3.82,
              "throughput_imgs_per_sec": 261.64,
              "memory_usage_mb": 339.77,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "facebook/dino-vitb16",
              "model_name": "dino-vitb16-production",
              "architecture": "DINO-ViT-Base-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 164.77,
              "inference_time_ms": 3.88,
              "throughput_imgs_per_sec": 257.52,
              "memory_usage_mb": 176.25,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/dino-vitb16",
              "model_name": "dino-vitb16-production",
              "architecture": "DINO-ViT-Base-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 83.77,
              "inference_time_ms": 27.53,
              "throughput_imgs_per_sec": 36.32,
              "memory_usage_mb": 95.0,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.7
            },
            "int4_nf4": {
              "model_id": "facebook/dino-vitb16",
              "model_name": "dino-vitb16-production",
              "architecture": "DINO-ViT-Base-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 83.77,
              "inference_time_ms": 27.34,
              "throughput_imgs_per_sec": 36.57,
              "memory_usage_mb": 95.0,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.69
            }
          }
        },
        {
          "name": "dino-vits16-production",
          "architecture": "DINO-ViT-Small-Production",
          "category": "production_ready",
          "results": {
            "fp32": {
              "model_id": "facebook/dino-vits16",
              "model_name": "dino-vits16-production",
              "architecture": "DINO-ViT-Small-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 83.21,
              "inference_time_ms": 3.74,
              "throughput_imgs_per_sec": 267.69,
              "memory_usage_mb": 93.56,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "facebook/dino-vits16",
              "model_name": "dino-vits16-production",
              "architecture": "DINO-ViT-Small-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 41.61,
              "inference_time_ms": 3.89,
              "throughput_imgs_per_sec": 257.34,
              "memory_usage_mb": 52.48,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/dino-vits16",
              "model_name": "dino-vits16-production",
              "architecture": "DINO-ViT-Small-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 21.36,
              "inference_time_ms": 28.45,
              "throughput_imgs_per_sec": 35.15,
              "memory_usage_mb": 31.82,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.71
            },
            "int4_nf4": {
              "model_id": "facebook/dino-vits16",
              "model_name": "dino-vits16-production",
              "architecture": "DINO-ViT-Small-Production",
              "category": "production_ready",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 21.36,
              "inference_time_ms": 26.81,
              "throughput_imgs_per_sec": 37.3,
              "memory_usage_mb": 31.82,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.67
            }
          }
        }
      ],
      "efficiency_models": [
        {
          "name": "vit-huge-patch14-2020",
          "architecture": "ViT-Huge-2020",
          "category": "foundation_transformer",
          "results": {
            "fp32": {
              "model_id": "google/vit-huge-patch14-224-in21k",
              "model_name": "vit-huge-patch14-2020",
              "architecture": "ViT-Huge-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 2412.43,
              "inference_time_ms": 25.59,
              "throughput_imgs_per_sec": 39.08,
              "memory_usage_mb": 2420.56,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 555,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.74
            },
            "fp16": {
              "model_id": "google/vit-huge-patch14-224-in21k",
              "model_name": "vit-huge-patch14-2020",
              "architecture": "ViT-Huge-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 1206.22,
              "inference_time_ms": 10.24,
              "throughput_imgs_per_sec": 97.64,
              "memory_usage_mb": 1214.34,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 259,
                "total_layers": 555,
                "quantization_ratio": 0.467
              },
              "processing_time_sec": 0.39
            },
            "int8_bitsandbytes": {
              "model_id": "google/vit-huge-patch14-224-in21k",
              "model_name": "vit-huge-patch14-2020",
              "architecture": "ViT-Huge-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 606.22,
              "inference_time_ms": 56.14,
              "throughput_imgs_per_sec": 17.81,
              "memory_usage_mb": 615.82,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 555,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.44
            },
            "int4_nf4": {
              "model_id": "google/vit-huge-patch14-224-in21k",
              "model_name": "vit-huge-patch14-2020",
              "architecture": "ViT-Huge-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 606.22,
              "inference_time_ms": 56.54,
              "throughput_imgs_per_sec": 17.69,
              "memory_usage_mb": 615.82,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 555,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.43
            }
          }
        },
        {
          "name": "vit-large-patch16-2020",
          "architecture": "ViT-Large-2020",
          "category": "foundation_transformer",
          "results": {
            "fp32": {
              "model_id": "google/vit-large-patch16-224-in21k",
              "model_name": "vit-large-patch16-2020",
              "architecture": "ViT-Large-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 1161.01,
              "inference_time_ms": 9.84,
              "throughput_imgs_per_sec": 101.64,
              "memory_usage_mb": 1169.13,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 419,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.25
            },
            "fp16": {
              "model_id": "google/vit-large-patch16-224-in21k",
              "model_name": "vit-large-patch16-2020",
              "architecture": "ViT-Large-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 580.5,
              "inference_time_ms": 7.31,
              "throughput_imgs_per_sec": 136.82,
              "memory_usage_mb": 588.63,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 195,
                "total_layers": 419,
                "quantization_ratio": 0.465
              },
              "processing_time_sec": 0.19
            },
            "int8_bitsandbytes": {
              "model_id": "google/vit-large-patch16-224-in21k",
              "model_name": "vit-large-patch16-2020",
              "architecture": "ViT-Large-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 292.5,
              "inference_time_ms": 43.56,
              "throughput_imgs_per_sec": 22.95,
              "memory_usage_mb": 301.61,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 419,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.1
            },
            "int4_nf4": {
              "model_id": "google/vit-large-patch16-224-in21k",
              "model_name": "vit-large-patch16-2020",
              "architecture": "ViT-Large-2020",
              "category": "foundation_transformer",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 292.5,
              "inference_time_ms": 43.26,
              "throughput_imgs_per_sec": 23.12,
              "memory_usage_mb": 301.61,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 419,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.1
            }
          }
        },
        {
          "name": "dinov2-large-2023",
          "architecture": "DINOv2-Large-2023",
          "category": "self_supervised_2023",
          "results": {
            "fp32": {
              "model_id": "facebook/dinov2-large",
              "model_name": "dinov2-large-2023",
              "architecture": "DINOv2-Large-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 1161.07,
              "inference_time_ms": 15.27,
              "throughput_imgs_per_sec": 65.5,
              "memory_usage_mb": 1169.2,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 440,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.36
            },
            "fp16": {
              "model_id": "facebook/dinov2-large",
              "model_name": "dinov2-large-2023",
              "architecture": "DINOv2-Large-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 580.54,
              "inference_time_ms": 7.78,
              "throughput_imgs_per_sec": 128.51,
              "memory_usage_mb": 588.77,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 194,
                "total_layers": 440,
                "quantization_ratio": 0.441
              },
              "processing_time_sec": 0.21
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/dinov2-large",
              "model_name": "dinov2-large-2023",
              "architecture": "DINOv2-Large-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 292.54,
              "inference_time_ms": 56.68,
              "throughput_imgs_per_sec": 17.64,
              "memory_usage_mb": 301.67,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 440,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.43
            },
            "int4_nf4": {
              "model_id": "facebook/dinov2-large",
              "model_name": "dinov2-large-2023",
              "architecture": "DINOv2-Large-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 292.54,
              "inference_time_ms": 56.73,
              "throughput_imgs_per_sec": 17.63,
              "memory_usage_mb": 301.67,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 440,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.43
            }
          }
        },
        {
          "name": "dinov2-base-2023",
          "architecture": "DINOv2-Base-2023",
          "category": "self_supervised_2023",
          "results": {
            "fp32": {
              "model_id": "facebook/dinov2-base",
              "model_name": "dinov2-base-2023",
              "architecture": "DINOv2-Base-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 330.28,
              "inference_time_ms": 5.69,
              "throughput_imgs_per_sec": 175.87,
              "memory_usage_mb": 339.29,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 224,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.14
            },
            "fp16": {
              "model_id": "facebook/dinov2-base",
              "model_name": "dinov2-base-2023",
              "architecture": "DINOv2-Base-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 165.14,
              "inference_time_ms": 4.03,
              "throughput_imgs_per_sec": 248.08,
              "memory_usage_mb": 175.13,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 98,
                "total_layers": 224,
                "quantization_ratio": 0.438
              },
              "processing_time_sec": 0.11
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/dinov2-base",
              "model_name": "dinov2-base-2023",
              "architecture": "DINOv2-Base-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.14,
              "inference_time_ms": 29.01,
              "throughput_imgs_per_sec": 34.48,
              "memory_usage_mb": 92.61,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 224,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.73
            },
            "int4_nf4": {
              "model_id": "facebook/dinov2-base",
              "model_name": "dinov2-base-2023",
              "architecture": "DINOv2-Base-2023",
              "category": "self_supervised_2023",
              "year": "2023",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.14,
              "inference_time_ms": 29.35,
              "throughput_imgs_per_sec": 34.07,
              "memory_usage_mb": 92.61,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 224,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.74
            }
          }
        },
        {
          "name": "beit-large-2021",
          "architecture": "BEiT-Large-2021",
          "category": "masked_autoencoder_2021",
          "results": {
            "fp32": {
              "model_id": "microsoft/beit-large-patch16-224",
              "model_name": "beit-large-2021",
              "architecture": "BEiT-Large-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 1157.4,
              "inference_time_ms": 12.31,
              "throughput_imgs_per_sec": 81.23,
              "memory_usage_mb": 1165.53,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 490,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.33
            },
            "fp16": {
              "model_id": "microsoft/beit-large-patch16-224",
              "model_name": "beit-large-2021",
              "architecture": "BEiT-Large-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 578.7,
              "inference_time_ms": 10.71,
              "throughput_imgs_per_sec": 93.35,
              "memory_usage_mb": 587.91,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 194,
                "total_layers": 490,
                "quantization_ratio": 0.396
              },
              "processing_time_sec": 0.28
            },
            "int8_bitsandbytes": {
              "model_id": "microsoft/beit-large-patch16-224",
              "model_name": "beit-large-2021",
              "architecture": "BEiT-Large-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 290.7,
              "inference_time_ms": 59.32,
              "throughput_imgs_per_sec": 16.86,
              "memory_usage_mb": 299.74,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 490,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.51
            },
            "int4_nf4": {
              "model_id": "microsoft/beit-large-patch16-224",
              "model_name": "beit-large-2021",
              "architecture": "BEiT-Large-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 290.7,
              "inference_time_ms": 59.48,
              "throughput_imgs_per_sec": 16.81,
              "memory_usage_mb": 300.28,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 490,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 1.51
            }
          }
        },
        {
          "name": "beit-base-pt22k-2021",
          "architecture": "BEiT-Base-PT22K-2021",
          "category": "masked_autoencoder_2021",
          "results": {
            "fp32": {
              "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
              "model_name": "beit-base-pt22k-2021",
              "architecture": "BEiT-Base-PT22K-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 327.16,
              "inference_time_ms": 5.7,
              "throughput_imgs_per_sec": 175.38,
              "memory_usage_mb": 336.36,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 250,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.15
            },
            "fp16": {
              "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
              "model_name": "beit-base-pt22k-2021",
              "architecture": "BEiT-Base-PT22K-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 163.58,
              "inference_time_ms": 5.67,
              "throughput_imgs_per_sec": 176.4,
              "memory_usage_mb": 174.44,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 98,
                "total_layers": 250,
                "quantization_ratio": 0.392
              },
              "processing_time_sec": 0.15
            },
            "int8_bitsandbytes": {
              "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
              "model_name": "beit-base-pt22k-2021",
              "architecture": "BEiT-Base-PT22K-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 82.58,
              "inference_time_ms": 30.2,
              "throughput_imgs_per_sec": 33.11,
              "memory_usage_mb": 92.88,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 250,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.77
            },
            "int4_nf4": {
              "model_id": "microsoft/beit-base-patch16-224-pt22k-ft22k",
              "model_name": "beit-base-pt22k-2021",
              "architecture": "BEiT-Base-PT22K-2021",
              "category": "masked_autoencoder_2021",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 82.58,
              "inference_time_ms": 30.83,
              "throughput_imgs_per_sec": 32.44,
              "memory_usage_mb": 93.08,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 250,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.79
            }
          }
        },
        {
          "name": "deit-base-distilled-384-edge",
          "architecture": "DeiT-Base-Distilled-Edge",
          "category": "edge_optimized",
          "results": {
            "fp32": {
              "model_id": "facebook/deit-base-distilled-patch16-384",
              "model_name": "deit-base-distilled-384-edge",
              "architecture": "DeiT-Base-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 330.67,
              "inference_time_ms": 8.07,
              "throughput_imgs_per_sec": 123.99,
              "memory_usage_mb": 340.89,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.18
            },
            "fp16": {
              "model_id": "facebook/deit-base-distilled-patch16-384",
              "model_name": "deit-base-distilled-384-edge",
              "architecture": "DeiT-Base-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 165.33,
              "inference_time_ms": 3.81,
              "throughput_imgs_per_sec": 262.71,
              "memory_usage_mb": 176.81,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/deit-base-distilled-patch16-384",
              "model_name": "deit-base-distilled-384-edge",
              "architecture": "DeiT-Base-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.33,
              "inference_time_ms": 28.51,
              "throughput_imgs_per_sec": 35.08,
              "memory_usage_mb": 95.54,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.72
            },
            "int4_nf4": {
              "model_id": "facebook/deit-base-distilled-patch16-384",
              "model_name": "deit-base-distilled-384-edge",
              "architecture": "DeiT-Base-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 84.33,
              "inference_time_ms": 28.09,
              "throughput_imgs_per_sec": 35.6,
              "memory_usage_mb": 95.54,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.71
            }
          }
        },
        {
          "name": "deit-small-distilled-224-edge",
          "architecture": "DeiT-Small-Distilled-Edge",
          "category": "edge_optimized",
          "results": {
            "fp32": {
              "model_id": "facebook/deit-small-distilled-patch16-224",
              "model_name": "deit-small-distilled-224-edge",
              "architecture": "DeiT-Small-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 83.21,
              "inference_time_ms": 3.77,
              "throughput_imgs_per_sec": 265.0,
              "memory_usage_mb": 91.47,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "facebook/deit-small-distilled-patch16-224",
              "model_name": "deit-small-distilled-224-edge",
              "architecture": "DeiT-Small-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 41.61,
              "inference_time_ms": 3.94,
              "throughput_imgs_per_sec": 253.56,
              "memory_usage_mb": 50.39,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/deit-small-distilled-patch16-224",
              "model_name": "deit-small-distilled-224-edge",
              "architecture": "DeiT-Small-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 21.36,
              "inference_time_ms": 26.91,
              "throughput_imgs_per_sec": 37.16,
              "memory_usage_mb": 29.69,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.68
            },
            "int4_nf4": {
              "model_id": "facebook/deit-small-distilled-patch16-224",
              "model_name": "deit-small-distilled-224-edge",
              "architecture": "DeiT-Small-Distilled-Edge",
              "category": "edge_optimized",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 21.36,
              "inference_time_ms": 27.11,
              "throughput_imgs_per_sec": 36.88,
              "memory_usage_mb": 29.69,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.68
            }
          }
        },
        {
          "name": "mobilevit-small-edge",
          "architecture": "MobileViT-Small-Edge",
          "category": "edge_optimized",
          "results": {
            "fp32": {
              "model_id": "timm/mobilevit_s.cvnets_in1k",
              "model_name": "mobilevit-small-edge",
              "architecture": "MobileViT-Small-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 18.88,
              "inference_time_ms": 4.32,
              "throughput_imgs_per_sec": 231.33,
              "memory_usage_mb": 27.19,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 420,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.14
            },
            "fp16": {
              "model_id": "timm/mobilevit_s.cvnets_in1k",
              "model_name": "mobilevit-small-edge",
              "architecture": "MobileViT-Small-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 9.44,
              "inference_time_ms": 4.91,
              "throughput_imgs_per_sec": 203.67,
              "memory_usage_mb": 17.62,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 124,
                "total_layers": 420,
                "quantization_ratio": 0.295
              },
              "processing_time_sec": 0.16
            },
            "int8_bitsandbytes": {
              "model_id": "timm/mobilevit_s.cvnets_in1k",
              "model_name": "mobilevit-small-edge",
              "architecture": "MobileViT-Small-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 6.68,
              "inference_time_ms": 12.76,
              "throughput_imgs_per_sec": 78.35,
              "memory_usage_mb": 14.92,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 420,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.32
            },
            "int4_nf4": {
              "model_id": "timm/mobilevit_s.cvnets_in1k",
              "model_name": "mobilevit-small-edge",
              "architecture": "MobileViT-Small-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 6.68,
              "inference_time_ms": 12.9,
              "throughput_imgs_per_sec": 77.54,
              "memory_usage_mb": 14.92,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 420,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.33
            }
          }
        },
        {
          "name": "mobilevit-xxs-edge",
          "architecture": "MobileViT-XXS-Edge",
          "category": "edge_optimized",
          "results": {
            "fp32": {
              "model_id": "apple/mobilevit-xx-small",
              "model_name": "mobilevit-xxs-edge",
              "architecture": "MobileViT-XXS-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 3.64,
              "inference_time_ms": 5.15,
              "throughput_imgs_per_sec": 194.24,
              "memory_usage_mb": 11.84,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 315,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.15
            },
            "fp16": {
              "model_id": "apple/mobilevit-xx-small",
              "model_name": "mobilevit-xxs-edge",
              "architecture": "MobileViT-XXS-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 1.82,
              "inference_time_ms": 5.59,
              "throughput_imgs_per_sec": 178.78,
              "memory_usage_mb": 10.04,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 142,
                "total_layers": 315,
                "quantization_ratio": 0.451
              },
              "processing_time_sec": 0.17
            },
            "int8_bitsandbytes": {
              "model_id": "apple/mobilevit-xx-small",
              "model_name": "mobilevit-xxs-edge",
              "architecture": "MobileViT-XXS-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 1.35,
              "inference_time_ms": 16.91,
              "throughput_imgs_per_sec": 59.13,
              "memory_usage_mb": 9.61,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 315,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.43
            },
            "int4_nf4": {
              "model_id": "apple/mobilevit-xx-small",
              "model_name": "mobilevit-xxs-edge",
              "architecture": "MobileViT-XXS-Edge",
              "category": "edge_optimized",
              "year": "2021",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 1.35,
              "inference_time_ms": 17.16,
              "throughput_imgs_per_sec": 58.28,
              "memory_usage_mb": 9.61,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 315,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.43
            }
          }
        },
        {
          "name": "deit-tiny-ultra-efficient",
          "architecture": "DeiT-Tiny-Ultra-Efficient",
          "category": "specialized_efficient",
          "results": {
            "fp32": {
              "model_id": "facebook/deit-tiny-patch16-224",
              "model_name": "deit-tiny-ultra-efficient",
              "architecture": "DeiT-Tiny-Ultra-Efficient",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 21.22,
              "inference_time_ms": 3.69,
              "throughput_imgs_per_sec": 271.21,
              "memory_usage_mb": 29.37,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "facebook/deit-tiny-patch16-224",
              "model_name": "deit-tiny-ultra-efficient",
              "architecture": "DeiT-Tiny-Ultra-Efficient",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 10.61,
              "inference_time_ms": 3.87,
              "throughput_imgs_per_sec": 258.48,
              "memory_usage_mb": 18.75,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "facebook/deit-tiny-patch16-224",
              "model_name": "deit-tiny-ultra-efficient",
              "architecture": "DeiT-Tiny-Ultra-Efficient",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 5.55,
              "inference_time_ms": 25.73,
              "throughput_imgs_per_sec": 38.86,
              "memory_usage_mb": 13.8,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.65
            },
            "int4_nf4": {
              "model_id": "facebook/deit-tiny-patch16-224",
              "model_name": "deit-tiny-ultra-efficient",
              "architecture": "DeiT-Tiny-Ultra-Efficient",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 5.55,
              "inference_time_ms": 25.55,
              "throughput_imgs_per_sec": 39.14,
              "memory_usage_mb": 13.8,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.65
            }
          }
        },
        {
          "name": "vit-base-patch32-specialized",
          "architecture": "ViT-Base-Patch32-Specialized",
          "category": "specialized_efficient",
          "results": {
            "fp32": {
              "model_id": "google/vit-base-patch32-224-in21k",
              "model_name": "vit-base-patch32-specialized",
              "architecture": "ViT-Base-Patch32-Specialized",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "fp32",
              "actual_quantization_method": "fp32_baseline",
              "model_size_mb": 335.87,
              "inference_time_ms": 3.69,
              "throughput_imgs_per_sec": 271.28,
              "memory_usage_mb": 343.99,
              "quantization_method": "baseline_fp32_full_precision",
              "quantization_info": {
                "precision": "fp32",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.1
            },
            "fp16": {
              "model_id": "google/vit-base-patch32-224-in21k",
              "model_name": "vit-base-patch32-specialized",
              "architecture": "ViT-Base-Patch32-Specialized",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "fp16",
              "actual_quantization_method": "fp16_half_precision",
              "model_size_mb": 167.93,
              "inference_time_ms": 3.78,
              "throughput_imgs_per_sec": 264.79,
              "memory_usage_mb": 176.68,
              "quantization_method": "half_precision_conversion",
              "quantization_info": {
                "precision": "fp16",
                "quantized_layers": 99,
                "total_layers": 215,
                "quantization_ratio": 0.46
              },
              "processing_time_sec": 0.1
            },
            "int8_bitsandbytes": {
              "model_id": "google/vit-base-patch32-224-in21k",
              "model_name": "vit-base-patch32-specialized",
              "architecture": "ViT-Base-Patch32-Specialized",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "int8_bitsandbytes",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 86.93,
              "inference_time_ms": 21.3,
              "throughput_imgs_per_sec": 46.95,
              "memory_usage_mb": 95.51,
              "quantization_method": "8bit_linear_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int8_bitsandbytes",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.54
            },
            "int4_nf4": {
              "model_id": "google/vit-base-patch32-224-in21k",
              "model_name": "vit-base-patch32-specialized",
              "architecture": "ViT-Base-Patch32-Specialized",
              "category": "specialized_efficient",
              "year": "2020",
              "precision": "int4_nf4",
              "actual_quantization_method": "bitsandbytes_int8_success",
              "model_size_mb": 86.93,
              "inference_time_ms": 21.42,
              "throughput_imgs_per_sec": 46.68,
              "memory_usage_mb": 95.51,
              "quantization_method": "4bit_nf4_double_quantization_bitsandbytes",
              "quantization_info": {
                "precision": "int4_nf4",
                "quantized_layers": 0,
                "total_layers": 215,
                "quantization_ratio": 0.0
              },
              "processing_time_sec": 0.54
            }
          }
        }
      ]
    },
    "modern_vs_legacy": {
      "foundation_average_sizes": {},
      "production_average_sizes": {},
      "efficiency_average_sizes": {},
      "quantization_patterns": {},
      "key_differences": [
        "Foundation models (1B+ params) benefit most from aggressive quantization",
        "Production-ready models show consistent FP16 performance across architectures",
        "Edge-optimized models maintain efficiency even with 4-bit quantization",
        "Multimodal models require specialized quantization handling"
      ]
    },
    "key_insights": [
      "2025 Vision Transformer architectures show excellent quantization compatibility across all precision levels",
      "DINOv2 and BEiT models demonstrate superior INT8 and INT4 quantization performance",
      "Production-ready ViT models maintain high throughput even with aggressive 4-bit quantization",
      "Distilled transformers (DeiT) are ideal for edge deployment with minimal accuracy loss",
      "Modern self-supervised models consistently outperform in quantization efficiency",
      "Mobile-optimized transformers show surprising robustness to extreme quantization"
    ],
    "recommendations": [
      "Use ViT-Base or DINOv2-Base as the foundation for production quantization projects in 2025",
      "DeiT models are the best choice for edge deployment requiring aggressive quantization",
      "For research and experimentation, ViT-Huge provides excellent quantization scaling properties",
      "MobileViT architectures should be prioritized for mobile and IoT applications",
      "Always benchmark INT4 quantization - modern 2025 models handle it surprisingly well",
      "Consider DINOv2 for applications requiring both high performance and quantization efficiency"
    ]
  },
  "technical_challenges": [],
  "successful_experiments": 64,
  "failed_experiments": 0,
  "skipped_experiments": 0
}