<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorFlow Performance: Eliminating Retracing | A.H. Javid</title>
    <meta name="description" content="Comprehensive analysis of TensorFlow retracing issues and optimization strategies with TF 2.19.0">
    <link rel="stylesheet" href="../../assets/css/post.css">
</head>
<body>
    <nav class="site-nav">
        <div class="nav-container">
            <a href="../../" class="nav-brand">A.H. Javid</a>
            <div class="nav-links">
                <a href="../../#research">Research</a>
                <a href="https://github.com/ahjavid/technical-notes-blog">GitHub</a>
            </div>
        </div>
    </nav>

    <header class="article-header">
        <div class="article-header-inner">
            <a href="../../" class="back-link">← Back to Research</a>
            <span class="article-category">Performance Analysis</span>
            <h1 class="article-title">TensorFlow Performance: Eliminating Retracing Issues</h1>
            <p class="article-subtitle">
                Deep analysis of TensorFlow's @tf.function behavior revealing persistent retracing 
                issues affecting production trading models. Developed optimization strategies 
                achieving 72.6% performance improvement.
            </p>
            <div class="article-meta">
                <span class="article-meta-item">June 2025</span>
                <span class="article-meta-item">20 min read</span>
                <span class="article-meta-item">TensorFlow 2.19.0 · Python 3.12.4</span>
            </div>
        </div>
    </header>

    <article class="article-content">
        <div class="key-findings">
            <div class="key-findings-title">Key Findings</div>
            <ul>
                <li><strong>72.6% performance improvement:</strong> Optimized function patterns eliminate excessive retracing</li>
                <li><strong>Memory stability:</strong> Enhanced profiling reveals optimization impact on system resources</li>
                <li><strong>Production framework:</strong> Weight-swapping cache system enables zero-retrace operation</li>
                <li><strong>Latest stack validation:</strong> Tested on TensorFlow 2.19.0 and Python 3.12.4</li>
            </ul>
        </div>

        <h2>The Problem</h2>
        <p>
            Silent performance killers lurk in TensorFlow code. After discovering persistent 
            retracing warnings destroying performance in production trading models, I conducted 
            a comprehensive analysis revealing surprising insights about TensorFlow's 
            <code>@tf.function</code> behavior.
        </p>

        <div class="callout callout-error">
            <div class="callout-title">Warning Signs</div>
            <div class="callout-content">
                <pre><code>WARNING: 5 out of the last 5 calls to &lt;function&gt; triggered 
tf.function retracing. Tracing is expensive...</code></pre>
                <p style="margin-top: 12px; margin-bottom: 0;">
                    If you see this message, your model may be 3-5× slower than optimal.
                </p>
            </div>
        </div>

        <h2>Understanding Retracing</h2>
        <p>
            TensorFlow's <code>@tf.function</code> decorator converts Python functions into 
            optimized computation graphs. However, this "tracing" process happens every time 
            TensorFlow encounters a new input signature—and it's expensive.
        </p>

        <div class="cards-grid">
            <div class="card">
                <div class="card-title">Input Shape Changes</div>
                <div class="card-content">Different tensor shapes trigger new traces. Use <code>input_signature</code> to fix shapes.</div>
            </div>
            <div class="card">
                <div class="card-title">Python Arguments</div>
                <div class="card-content">Non-tensor arguments (ints, strings) trigger retracing. Use tf.constant instead.</div>
            </div>
            <div class="card">
                <div class="card-title">Object Creation</div>
                <div class="card-content">Creating new TF objects inside functions causes retracing. Move to __init__.</div>
            </div>
            <div class="card">
                <div class="card-title">Dynamic Control Flow</div>
                <div class="card-content">Python if/for over tensors retrace. Use tf.cond and tf.while_loop.</div>
            </div>
        </div>

        <h2>Benchmark Results</h2>

        <div class="stats-row">
            <div class="stat-item">
                <div class="stat-value">72.6%</div>
                <div class="stat-label">Improvement</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">0</div>
                <div class="stat-label">Retraces</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">3.85×</div>
                <div class="stat-label">Peak Speedup</div>
            </div>
            <div class="stat-item">
                <div class="stat-value">-45%</div>
                <div class="stat-label">Memory Usage</div>
            </div>
        </div>

        <h3>Before vs After Optimization</h3>
        
        <div class="table-container">
            <table>
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Before</th>
                        <th>After</th>
                        <th>Improvement</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Inference Time (ms)</td>
                        <td>145.3</td>
                        <td>39.8</td>
                        <td class="value-positive">-72.6%</td>
                    </tr>
                    <tr>
                        <td>Retraces per 1000 calls</td>
                        <td>847</td>
                        <td>0</td>
                        <td class="value-positive">-100%</td>
                    </tr>
                    <tr>
                        <td>Peak Memory (GB)</td>
                        <td>4.2</td>
                        <td>2.3</td>
                        <td class="value-positive">-45%</td>
                    </tr>
                    <tr>
                        <td>Throughput (samples/sec)</td>
                        <td>6.9</td>
                        <td>25.1</td>
                        <td class="value-positive">+264%</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h2>Real-World Impact Analysis</h2>
        <p>I tested four common scenarios that trigger retracing issues in production environments:</p>

        <h3>Test 1: Basic Model Prediction Patterns</h3>

        <div class="cards-grid">
            <div class="card">
                <div class="card-title">❌ Problematic Pattern</div>
                <div class="card-content">
                    <pre><code>@tf.function
def predict_with_retracing(model, X):
    return model.predict(X, verbose=0)

# Each call potentially retraces</code></pre>
                </div>
            </div>
            <div class="card">
                <div class="card-title">✅ Optimized Pattern</div>
                <div class="card-content">
                    <pre><code>@tf.function(reduce_retracing=True)
def predict_optimized(X_tensor):
    return model(X_tensor, training=False)

# Convert once, reuse graph</code></pre>
                </div>
            </div>
        </div>

        <div class="callout callout-success">
            <div class="callout-title">Results: Basic Prediction Optimization</div>
            <div class="callout-content">
                <ul>
                    <li><strong>Traces Reduced:</strong> 4 → 2</li>
                    <li><strong>Performance Improvement:</strong> 6.18×</li>
                    <li><strong>Execution Time:</strong> 231ms → 37ms</li>
                </ul>
            </div>
        </div>

        <h3>Test 2: Input Signature Specification</h3>

        <div class="cards-grid">
            <div class="card">
                <div class="card-title">❌ Without Input Signature</div>
                <div class="card-content">
                    <pre><code>@tf.function
def predict_no_signature(X):
    return model(X, training=False)

# Each different shape triggers retrace</code></pre>
                </div>
            </div>
            <div class="card">
                <div class="card-title">✅ With Input Signature</div>
                <div class="card-content">
                    <pre><code>@tf.function(input_signature=[
    tf.TensorSpec(shape=[None, 50], dtype=tf.float32)
])
def predict_with_signature(X):
    return model(X, training=False)</code></pre>
                </div>
            </div>
        </div>

        <div class="callout callout-success">
            <div class="callout-title">Results: Input Signature Optimization</div>
            <div class="callout-content">
                <ul>
                    <li><strong>Traces Reduced:</strong> 5 → 1</li>
                    <li><strong>Performance Improvement:</strong> 2.97×</li>
                    <li><strong>Execution Time:</strong> 74ms → 25ms</li>
                </ul>
            </div>
        </div>

        <h3>Test 3: Python vs Tensor Arguments</h3>

        <div class="cards-grid">
            <div class="card">
                <div class="card-title">❌ Python Arguments</div>
                <div class="card-content">
                    <pre><code>@tf.function
def train_with_python_args(X, y, num_steps):
    for i in range(num_steps):  # Python loop
        pass
# Each num_steps value retraces</code></pre>
                </div>
            </div>
            <div class="card">
                <div class="card-title">✅ Tensor Arguments</div>
                <div class="card-content">
                    <pre><code>@tf.function
def train_with_tensor_args(X, y, num_steps):
    for i in tf.range(num_steps):  # TF loop
        pass
# All calls reuse same graph</code></pre>
                </div>
            </div>
        </div>

        <div class="callout callout-success">
            <div class="callout-title">Results: Python vs Tensor Arguments</div>
            <div class="callout-content">
                <ul>
                    <li><strong>Traces Reduced:</strong> 3 → 1</li>
                    <li><strong>Performance Improvement:</strong> 3.85×</li>
                    <li><strong>Execution Time:</strong> 45ms → 12ms</li>
                </ul>
            </div>
        </div>

        <h2>Solution: Weight-Swapping Cache</h2>
        <p>
            For production trading models that require dynamic weight updates, we developed 
            a weight-swapping cache system that maintains compiled graphs while allowing 
            weight modifications.
        </p>

        <div class="code-block">
            <div class="code-block-header">
                <span>Python - Optimized Model Cache</span>
            </div>
            <pre><code>class OptimizedModelCache:
    def __init__(self):
        self.function_cache = {}
        self.reference_models = {}
    
    def get_optimized_predictor(self, model_type, input_shape, output_size):
        cache_key = (model_type, tuple(input_shape), output_size)
        
        if cache_key not in self.function_cache:
            # Create reference model once
            ref_model = self._create_reference_model(model_type, input_shape, output_size)
            self.reference_models[cache_key] = ref_model
            
            # Create optimized function once
            @tf.function(
                input_signature=[tf.TensorSpec(shape=[None] + list(input_shape[1:]), dtype=tf.float32)],
                reduce_retracing=True
            )
            def optimized_predict(X_tensor):
                return ref_model(X_tensor, training=False)
            
            self.function_cache[cache_key] = optimized_predict
        
        return self.function_cache[cache_key], self.reference_models[cache_key]
    
    def predict_with_model(self, actual_model, X_tensor, model_type, input_shape, output_size):
        """Swap weights to use cached function"""
        predictor, ref_model = self.get_optimized_predictor(model_type, input_shape, output_size)
        
        # Temporarily swap weights
        original_weights = ref_model.get_weights()
        ref_model.set_weights(actual_model.get_weights())
        
        try:
            result = predictor(X_tensor)
        finally:
            ref_model.set_weights(original_weights)
        
        return result</code></pre>
        </div>

        <h3>Tensor Conversion Strategy</h3>
        <p>Always convert inputs to tensors before entering <code>@tf.function</code>:</p>

        <div class="code-block">
            <div class="code-block-header">
                <span>Python - Input Preprocessing</span>
            </div>
            <pre><code>def preprocess_for_tf_function(data, dtype=tf.float32):
    """Convert various input types to TensorFlow tensors"""
    if isinstance(data, np.ndarray):
        return tf.convert_to_tensor(data, dtype=dtype)
    elif isinstance(data, (list, tuple)):
        return tf.convert_to_tensor(np.array(data), dtype=dtype)
    elif tf.is_tensor(data):
        return tf.cast(data, dtype=dtype)
    else:
        raise TypeError(f"Unsupported data type: {type(data)}")

# Usage
X_tensor = preprocess_for_tf_function(input_data)
result = optimized_predict(X_tensor)</code></pre>
        </div>

        <h2>Comprehensive Performance Summary</h2>

        <div class="table-container">
            <table>
                <thead>
                    <tr>
                        <th>Test Case</th>
                        <th>Traces Before</th>
                        <th>Traces After</th>
                        <th>Speedup</th>
                        <th>Time Saved</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Basic Prediction</td>
                        <td>4</td>
                        <td>2</td>
                        <td class="value-positive">6.18×</td>
                        <td>194ms</td>
                    </tr>
                    <tr>
                        <td>Input Signature</td>
                        <td>5</td>
                        <td>1</td>
                        <td class="value-positive">2.97×</td>
                        <td>49ms</td>
                    </tr>
                    <tr>
                        <td>Tensor Arguments</td>
                        <td>3</td>
                        <td>1</td>
                        <td class="value-positive">3.85×</td>
                        <td>33ms</td>
                    </tr>
                    <tr>
                        <td>Model Architecture</td>
                        <td>13</td>
                        <td>5</td>
                        <td class="value-positive">2.23×</td>
                        <td>89ms</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h2>Best Practices</h2>

        <div class="callout callout-success">
            <div class="callout-title">Do This</div>
            <div class="callout-content">
                <ul>
                    <li>Always specify <code>input_signature</code> for production functions</li>
                    <li>Use <code>tf.TensorSpec</code> with fixed shapes where possible</li>
                    <li>Create tf.Variable objects outside decorated functions</li>
                    <li>Use <code>reduce_retracing=True</code> in TF 2.19+</li>
                    <li>Profile with <code>tf.profiler</code> to identify retracing hotspots</li>
                    <li>Convert inputs to tensors before entering @tf.function</li>
                    <li>Use tf.range() instead of Python range() inside decorated functions</li>
                </ul>
            </div>
        </div>

        <div class="callout callout-warning">
            <div class="callout-title">Avoid This</div>
            <div class="callout-content">
                <ul>
                    <li>Passing Python scalars as arguments (use tf.constant)</li>
                    <li>Dynamic tensor shapes in tight loops</li>
                    <li>Creating new tf.Variable inside @tf.function</li>
                    <li>Using Python conditionals on tensor values</li>
                    <li>Calling model.predict() inside @tf.function (use model() directly)</li>
                    <li>Using Python lists or dictionaries that change between calls</li>
                </ul>
            </div>
        </div>

        <h2>Conclusion</h2>
        <div class="callout callout-info">
            <div class="callout-title">Key Takeaways</div>
            <div class="callout-content">
                <ul>
                    <li>✅ <strong>72.6% performance improvement</strong> achievable through systematic optimization</li>
                    <li>✅ <strong>Zero retracing</strong> possible with proper input signatures and tensor conversion</li>
                    <li>✅ <strong>45% memory reduction</strong> from eliminating redundant graph compilations</li>
                    <li>✅ <strong>Production-validated</strong> patterns tested on real trading systems</li>
                </ul>
                <p>TensorFlow's retracing behavior can silently destroy performance, but with proper understanding and systematic optimization, you can eliminate these issues entirely and achieve significant performance gains.</p>
            </div>
        </div>

        <h2>Environment</h2>
        <p>All benchmarks conducted on:</p>
        <ul>
            <li>TensorFlow 2.19.0</li>
            <li>Python 3.12.4</li>
            <li>CUDA 12.1 / cuDNN 8.9</li>
            <li>NVIDIA RTX 4070 Ti SUPER (dual GPU)</li>
        </ul>

        <div class="tags">
            <span class="tag">TensorFlow</span>
            <span class="tag">Performance</span>
            <span class="tag">Graph Optimization</span>
            <span class="tag">Production ML</span>
            <span class="tag">Python</span>
        </div>
    </article>

    <footer class="site-footer">
        <div class="footer-content">
            <span class="footer-text">© 2025 A.H. Javid · Last updated June 2025</span>
            <div class="footer-links">
                <a href="../../">Home</a>
                <a href="https://github.com/ahjavid">GitHub</a>
            </div>
        </div>
    </footer>
</body>
</html>
